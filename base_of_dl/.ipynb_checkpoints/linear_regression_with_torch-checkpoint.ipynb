{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as Data\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs = 2\n",
    "num_examples = 1000\n",
    "true_w = [2, -3.4]\n",
    "true_b = 4.2\n",
    "features = torch.randn(num_examples, num_inputs,\n",
    "                       dtype=torch.float32)\n",
    "labels = true_w[0] * features[:, 0] + true_w[1] * features[:, 1] + true_b\n",
    "labels += torch.tensor(np.random.normal(0, 0.01, size=labels.size()),\n",
    "                       dtype=torch.float32) # 加入噪声"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_svg_display():\n",
    "    # 用矢量图显示\n",
    "    display.set_matplotlib_formats('svg')\n",
    "\n",
    "def set_figsize(figsize=(10, 6)):\n",
    "    use_svg_display()\n",
    "    # 设置图的尺寸\n",
    "    plt.rcParams['figure.figsize'] = figsize\n",
    "\n",
    "# # 在../d2lzh_pytorch里面添加上面两个函数后就可以这样导入\n",
    "# import sys\n",
    "# sys.path.append(\"..\")\n",
    "# from d2lzh_pytorch import * \n",
    "\n",
    "plt.scatter(features[:, 0].numpy(), labels.numpy(), s=1, c='r', label=\"feature 1\");\n",
    "plt.scatter(features[:, 1].numpy(), labels.numpy(), s=1, c='b', label=\"feature 2\");\n",
    "plt.title(\"true data\")\n",
    "plt.legend(loc=\"upper right\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "dataset = Data.TensorDataset(features, labels) # 合并特征和标签得到数据集\n",
    "data_iter = Data.DataLoader(dataset, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for X, y in data_iter:\n",
    "    print(X.shape, y.shape)\n",
    "    print(X)\n",
    "    print(y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义自己的类\n",
    "class LinearNet(nn.Module):\n",
    "    def __init__(self, n_features) -> None:\n",
    "        super(LinearNet, self).__init__()\n",
    "        self.linear = nn.Linear(n_features, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "mynet = LinearNet(num_inputs)\n",
    "# nn.Sequential()是一个有序的容器，传入每层网络会被按顺序添加到计算图中\n",
    "# mynet = nn.Sequential(\n",
    "#     nn.Linear(num_inputs, 1)\n",
    "# )\n",
    "print(mynet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过nn.parameters()查看模型所有可学习参数\n",
    "for param in mynet.parameters():\n",
    "    print(param) # w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化模型参数, 对mynet模型的linear层进行初始化\n",
    "nn.init.normal_(mynet.linear.weight, mean=0, std=0.01)\n",
    "nn.init.constant_(mynet.linear.bias, val=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义损失函数\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# 定义优化算法\n",
    "optimizer = torch.optim.SGD(mynet.parameters(), lr=0.03)\n",
    "\n",
    "# 为子网络设置不同的学习率\n",
    "# optimizer =optim.SGD([\n",
    "#                 # 如果对某个参数不指定学习率，就使用最外层的默认学习率\n",
    "#                 {'params': net.subnet1.parameters()}, # lr=0.03\n",
    "#                 {'params': net.subnet2.parameters(), 'lr': 0.01}\n",
    "#             ], lr=0.03)\n",
    "\n",
    "print(optimizer)\n",
    "\n",
    "# 调整学习率\n",
    "for param_group in optimizer.param_groups:\n",
    "    param_group['lr'] *= 0.1 # 学习率为之前的0.1倍\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练模型\n",
    "def train(data_iter, model, loss_fn, optimizer):\n",
    "    for X, y in data_iter:\n",
    "        output = model(X)\n",
    "        loss = loss_fn(output, y.view(-1, 1))\n",
    "\n",
    "        optimizer.zero_grad() # 梯度清零，等价于mynet.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step() # 进行一次迭代\n",
    "    return loss\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    loss = train(data_iter, mynet, loss_fn, optimizer)\n",
    "    print('epoch %d, loss: %f' % (epoch, loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从net获得需要的层，并访问其权重（weight）和偏差（bias）\n",
    "dense = mynet.linear\n",
    "print(true_w, dense.weight)\n",
    "print(true_b, dense.bias)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3e357e7cff7c5b1dd6383ad260e87ce8a8a7ab5594eb652d9253b84adf90c718"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
